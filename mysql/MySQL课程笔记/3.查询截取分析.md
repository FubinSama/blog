# 3. 查询截取分析

调优分析步骤：

1. 观察，至少跑一天，看看生产的慢SQL情况
2. 开启慢查询日志，设置阈值，比如超过5秒钟的就是慢SQL，并将它抓取出来
3. explain+慢SQL分析
4. show profile
5. 运维经理或DBA进行SQL数据库服务器的参数调优。

总结：

1. 慢查询的开启并捕获
2. explain+慢SQL分析
3. show profile查询SQL在MySQL服务器里面的执行细节和生命周期情况
4. SQL数据库服务器的参数调优

## 查询优化

### 1.永远小表驱动大表

因为

```JAVA
for(int i=0; i<5; ++i) {
    for(int j=0; j<1000; ++j) {
        //TODO
    }
}
```

和

```JAVA
for(int i=0; i<1000; ++i) {
    for(int j=0; j<5; ++j) {
        //TODO
    }
}
```

结果一样，但是效率完全不同。这是因为下面的多了很多次磁盘IO

因此（MySQL8好像不会这样，两种写法都会自动小表驱动大表）：

```SQL
select * from A where id in(select id from B);
## 相当于
for select id from B
    for select * from A where A.id = B.id;
```

当B表的数据集远小于A表的数据集时，用in由于exists

```SQL
select * from A where exists(select 1 from B where B.id = A.id);
## 相当于
for select * from A
    for select 1 from B where B.id = A.id;
```

当A表的数据集小于B表的数据集时，用exists优于in

### 2. order by的排序优化

```SQL
create table tblA(
    #id int primary key not null auto_increment,
    age int,
    birth timestamp not null
);

insert into tblA(age, birth) values
    (22, now()),
    (23, now()),
    (24, now());

create index idx_A_ageBirth on tblA(age, birth);

select * from tblA;

# case

## 1. 不会产生filesort
explain select * from tblA where age > 20 order by age;
## 2.不会产生filesort
explain select * from tblA where age > 20 order by age, birth;
## 3.会产生filesort
explain select * from tblA where age > 20 order by birth;
## 4.会产生filesort
explain select * from tblA where age > 20 order by birth, age;
## 5.会产生filesort
explain select * from tblA order by birth;
## 6.会产生filesort
explain select * from tblA where birth > '2016-01-28 00:00:00' order by birth;
## 7.不会产生filesort
explain select * from tblA where birth > '2016-01-28 00:00:00' order by age;
## 8.会产生filesort，因为一个升，一个降
explain select * from tblA order by age asc, birth desc;
```

1. order by子句尽量使用index方式排序，避免使用filesort方式排序
2. 尽可能在索引列上完成排序操作，遵照索引建的最佳左前缀
3. 如果不在索引列上，filesort有两种算法：mysql就要启动双路排序（MySQL4.1之前使用这种方法，会产生两次磁盘IO）和单路排序（默认的排序方式，使用sort buffer进行排序，如果buffer无法容纳所有字段，会导致多次磁盘IO）

MySQL支持两种方式的排序：

1. Using index：扫描索引排序，效率高
2. Using filesort：文件排序，效率低

order by 满足两种情况，会使用index方式排序：

1. order by语句使用索引最左前列
2. 使用where子句与order by子句条件列组合满足索引最左前列

## 3.group by的优化

1. group by实际上是先排序后进行分组，遵照索引建的最佳左前缀
2. 当无法使用索引列时，增大max_length_for_sort_data参数的设置+增大sort_buffer_size参数的设置
3. where高于having，能写在where限定的条件就不要去having限定了

## 慢查询日志

### 是什么

MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阈值的语句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。long_query_time的默认值为10，意思是运行10s以上的语句。

### 怎么玩

#### 说明

**默认情况下，MySQL数据库没有开启慢查询日志**，需要我们手动来设置这个参数
**如果不是调优需要的话，一般不建议启动该参数**，因为开启慢查询日志会带来一定的性能影响。慢查询日志支持将日志记录写入文件（默认为`/var/lib/mysql/主机名-slow.log`）

#### 查看及开启

查看：`show variables like '%slow_query_log%';`
开启：`set global slow_query_log = 1;`，只对当前数据库生效，如果MySQL重启后则失效。设置完重新开启一个会话，才能查到已做的修改

#### 阈值

查看：`show variables like 'long_query_time%';`，慢查询是大于该阈值的SQL，而不是大于等于
修改：`set global long_query_time=3;`

### 日志分析工具`mysqldumpslow`

#### 帮助信息

`mysqldumpslow --help`查看帮助信息

s：表示按照何种方式排序
c：访问次数
l：锁定时间
r：返回记录
t：查询时间
al：平均锁定时间
ar：平均返回记录数
at：平均查询时间
t：即为返回前面多少条的数据
g：后面搭配一个正则匹配模式，大小写不敏感的

常用的查询命令：

1. 得到返回记录集最多的10个SQL：`mysqldumpslow -s r -t 10 /var/lib/mysql/wfbpc-slow.log;`
2. 得到访问次数最多的10个SQL：`mysqldumpslow -s c -t 10 /var/lib/mysql/wfbpc-slow.log;`
3. 得到按照时间排序的前10条里面含有左连接的查询语句：`mysqldumpslow -s t -t 10 -g "left join" /var/lib/mysql/wfbpc-slow.log;`

ps：建议使用这些命令时结合`|`和`more`：`mysqldumpslow -s r -t 10 /var/lib/mysql/wfbpc-slow.log | more`

## 批量数据脚本

当二进制日志启用后，这个变量就会启用。它控制是否可以信任存储函数创建者，不会创建写入二进制日志引起不安全事件的存储函数。如果设置为0（默认值），用户不得创建或修改存储函数，除非它们具有除CREATE ROUTINE或ALTER ROUTINE特权之外的SUPER权限。 设置为0还强制使用DETERMINISTIC特性或READS SQL DATA或NO SQL特性声明函数的限制。 如果变量设置为1，MySQL不会对创建存储函数实施这些限制。 此变量也适用于触发器的创建。

因为，当开启了二进制日志后，要想创建函数和存储过程，就要开启该变量

```SQL
show variables like 'log_bin_trust_function_creators';
set global log_bin_trust_function_creators=1;
```

### 创建数据库，表，函数，存储过程，并调用

```SQL
# 新建库
create database bigData;
use bigData;

# 1. 建表dept
create table dept(
    id int unsigned primary key auto_increment,
    deptno mediumint unsigned not null default 0,
    dname varchar(20) not null default "",
    loc varchar(13) not null default ""
) engine=InnoDB default charset=utf8;

# 2. 建表emp
create table emp(
    id int unsigned primary key auto_increment,
    empno mediumint unsigned not null default 0, /*编号*/
    ename varchar(20) not null default "", /*名字*/
    job varchar(9) not null default "", /*工作*/
    mgr mediumint unsigned not null default 0, /*上级编号*/
    hiredate date not null, /*入职时间*/
    sal decimal(7,2) not null, /*薪水*/
    comm decimal(7,2) not null, /*红利*/
    deptno mediumint unsigned not null default 0 /*部门编号*/
)engine=InnoDB default charset=utf8;

# 随机产生字符串的函数
delimiter $$
create function rand_string(n int) returns varchar(255)
begin
        declare chars_str varchar(100) default 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';
        declare return_str varchar(255) default '';
        declare i int default 0;
        while i < n do
                set return_str=concat(return_str, substring(chars_str, floor(1+rand()*52), 1));
                set i = i + 1;
        end while;
        return return_str;
end $$
delimiter ;

# 随机产生部门编号的函数
delimiter $$
create function rand_num() returns int(5)
begin
        declare i int default 0;
        set i = floor(100 + rand() * 10);
return i;
end $$
delimiter ;

# 往emp表中插入数据的存储过程
delimiter $$
create procedure insert_emp(in start int(10), in max_num int(10))
begin
        declare i int default 0;
        set autocommit = 0;
        repeat
            set i = i + 1;
            insert into emp(empno, ename, job, mgr, hiredate, sal, comm, deptno) values((start+i), rand_string(6), 'SALESMAN', 0001, curdate(), 2000, 400, rand_num());
            until i = max_num
        end repeat;
        commit;
        set autocommit = 1;
end $$
delimiter ;

# 往dept表中插入数据的存储过程
delimiter $$
create procedure insert_dept(in start int(10), in max_num int(10))
begin
        declare i int default 0;
        set autocommit = 0;
        repeat
            set i = i + 1;
            insert into dept(deptno, dname, loc) values((start+i), rand_string(10), rand_string(8));
            until i = max_num
        end repeat;
        commit;
        set autocommit = 1;
end $$
delimiter ;

# 调用存储过程dept

call insert_dept(100001, 500000);

# 调用存储过程emp

call insert_emp(100001, 5000000);
```

## Show Profile

### 是什么

是MySQL提供可以用来分析当前会话中语句执行的资源消耗情况。可以用于SQL的调优的测量

默认情况下关闭。默认只保存15条

### 开启和查看的命令

```SQL
# 查看profile是否开启和开启的命令
show variables like 'profiling';
set profiling = on;
```

### 查看结果

```SQL
show profiles;
```

### 诊断SQL

profile可以查询的类型：

1. all：显示所有的开销信息
2. block io：显示块io相关开销
3. context switches：上下文切换相关开销
4. cpu：显示cpu相关开销信息
5. ipc：显示发送和接收相关开销信息
6. memory：显示内存相关开销信息
7. page faults：显示页面错误相关开销信息
8. source：显示和source_function，source_file，source_line相关的开销信息
9. swaps：显示交换次数相关的开销信息

```SQL
show profile cpu, block io for query id编号;
```

导致SQL变慢的主要原因是出现如下过程：

- `converting HEAP to MyISAM`查询结果太大，内存都不够用了往磁盘上搬了
- `creating tmp table`创建临时表，拷贝数据到临时表，用完再删除
- `copying to tmp table on disk`把内存中临时表复制到磁盘
- `locked`

## 全局查询日志

ps：**不要在生产环境开启这个功能**

### 配置开启

在`my.cnf`中，设置如下：

```SH
# 开启
general_log=1
# 记录日志文件的路径
general_log_file=/path/logfile
# 输出格式
log_output=FILE
```

### 编码启用

```SQL
set global general_log=1;
set global log_output='TABLE';
```

可以使用`select * from mysql.general_log`命令查看